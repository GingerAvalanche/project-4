{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1492fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.x  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.5.0'\n",
    "spark_version = 'spark-3.5.0'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3e7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import packages\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23ab1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------------+------------+-----------+-------------------+-----------+--------------+---------------+-------+--------+------+\n",
      "|age|sex|chest_pain_type|resting_bp_s|cholesterol|fasting_blood_sugar|resting_ecg|max_heart_rate|exercise_angina|oldpeak|ST_slope|target|\n",
      "+---+---+---------------+------------+-----------+-------------------+-----------+--------------+---------------+-------+--------+------+\n",
      "| 40|  1|              2|         140|        289|                  0|          0|           172|              0|    0.0|       1|     0|\n",
      "| 49|  0|              3|         160|        180|                  0|          0|           156|              0|    1.0|       2|     1|\n",
      "| 37|  1|              2|         130|        283|                  0|          1|            98|              0|    0.0|       1|     0|\n",
      "| 48|  0|              4|         138|        214|                  0|          0|           108|              1|    1.5|       2|     1|\n",
      "| 54|  1|              3|         150|        195|                  0|          0|           122|              0|    0.0|       1|     0|\n",
      "| 39|  1|              3|         120|        339|                  0|          0|           170|              0|    0.0|       1|     0|\n",
      "| 45|  0|              2|         130|        237|                  0|          0|           170|              0|    0.0|       1|     0|\n",
      "| 54|  1|              2|         110|        208|                  0|          0|           142|              0|    0.0|       1|     0|\n",
      "| 37|  1|              4|         140|        207|                  0|          0|           130|              1|    1.5|       2|     1|\n",
      "| 48|  0|              2|         120|        284|                  0|          0|           120|              0|    0.0|       1|     0|\n",
      "| 37|  0|              3|         130|        211|                  0|          0|           142|              0|    0.0|       1|     0|\n",
      "| 58|  1|              2|         136|        164|                  0|          1|            99|              1|    2.0|       2|     1|\n",
      "| 39|  1|              2|         120|        204|                  0|          0|           145|              0|    0.0|       1|     0|\n",
      "| 49|  1|              4|         140|        234|                  0|          0|           140|              1|    1.0|       2|     1|\n",
      "| 42|  0|              3|         115|        211|                  0|          1|           137|              0|    0.0|       1|     0|\n",
      "| 54|  0|              2|         120|        273|                  0|          0|           150|              0|    1.5|       2|     0|\n",
      "| 38|  1|              4|         110|        196|                  0|          0|           166|              0|    0.0|       2|     1|\n",
      "| 43|  0|              2|         120|        201|                  0|          0|           165|              0|    0.0|       1|     0|\n",
      "| 60|  1|              4|         100|        248|                  0|          0|           125|              0|    1.0|       2|     1|\n",
      "| 36|  1|              2|         120|        267|                  0|          0|           160|              0|    3.0|       2|     1|\n",
      "+---+---+---------------+------------+-----------+-------------------+-----------+--------------+---------------+-------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "\n",
    "url = \"https://ale-work-123.s3.us-west-1.amazonaws.com/heart_statlog_cleveland_hungary_final_clean.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"age\", IntegerType(), False),\n",
    "        StructField(\"sex\", IntegerType(), False),\n",
    "        StructField(\"chest_pain_type\", IntegerType(), False),\n",
    "        StructField(\"resting_bp_s\", IntegerType(), False),\n",
    "        StructField(\"cholesterol\", IntegerType(), False),\n",
    "        StructField(\"fasting_blood_sugar\", IntegerType(), False),\n",
    "        StructField(\"resting_ecg\", IntegerType(), False),\n",
    "        StructField(\"max_heart_rate\", IntegerType(), False),\n",
    "        StructField(\"exercise_angina\", IntegerType(), False),\n",
    "        StructField(\"oldpeak\", FloatType(), False),\n",
    "        StructField(\"ST_slope\", IntegerType(), False),\n",
    "        StructField(\"target\", IntegerType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.read.csv(SparkFiles.get(\"heart_statlog_cleveland_hungary_final_clean.csv\"), sep=\",\", header=True, schema=schema)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e9b309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- chest_pain_type: integer (nullable = true)\n",
      " |-- resting_bp_s: integer (nullable = true)\n",
      " |-- cholesterol: integer (nullable = true)\n",
      " |-- fasting_blood_sugar: integer (nullable = true)\n",
      " |-- resting_ecg: integer (nullable = true)\n",
      " |-- max_heart_rate: integer (nullable = true)\n",
      " |-- exercise_angina: integer (nullable = true)\n",
      " |-- oldpeak: float (nullable = true)\n",
      " |-- ST_slope: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86234d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------------+------------+-----------+-------------------+-----------+--------------+---------------+-------+--------+-----+--------------------+\n",
      "|age|sex|chest_pain_type|resting_bp_s|cholesterol|fasting_blood_sugar|resting_ecg|max_heart_rate|exercise_angina|oldpeak|ST_slope|label|            features|\n",
      "+---+---+---------------+------------+-----------+-------------------+-----------+--------------+---------------+-------+--------+-----+--------------------+\n",
      "| 40|  1|              2|         140|        289|                  0|          0|           172|              0|    0.0|       1|    0|[40.0,1.0,2.0,140...|\n",
      "| 49|  0|              3|         160|        180|                  0|          0|           156|              0|    1.0|       2|    1|[49.0,0.0,3.0,160...|\n",
      "| 37|  1|              2|         130|        283|                  0|          1|            98|              0|    0.0|       1|    0|[37.0,1.0,2.0,130...|\n",
      "| 48|  0|              4|         138|        214|                  0|          0|           108|              1|    1.5|       2|    1|[48.0,0.0,4.0,138...|\n",
      "| 54|  1|              3|         150|        195|                  0|          0|           122|              0|    0.0|       1|    0|[54.0,1.0,3.0,150...|\n",
      "+---+---+---------------+------------+-----------+-------------------+-----------+--------------+---------------+-------+--------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "df = df.withColumnRenamed('target', 'label')\n",
    "\n",
    "assembler = VectorAssembler(inputCols=df.columns[:-1], outputCol='features')\n",
    "df = assembler.transform(df)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16aaee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "459a2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logistic_regression = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model = logistic_regression.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d64211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8389\n",
      "Precision: 0.8389\n",
      "Recall: 0.8389\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_data)\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Accuracy, Precision, and Recall\n",
    "multi_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\n",
    "precision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e018733f",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "The model for predicting heart disease based upon the acquired data is about 84% accurate. This isn't too bad, overall, though I don't think this model would be acceptable for general use, as a recall of 84% means that 16% heart disease patients could go undiagnosed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
